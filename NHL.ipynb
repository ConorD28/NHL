{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rq6xsPJUvkXO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from sklearn.decomposition import PCA\n",
        "%matplotlib inline\n",
        "df = pd.read_csv('NHL Upload.csv')\n",
        "df.drop(df.tail(1).index,\n",
        "        inplace = True)\n",
        "df_NP = df.drop(columns=df.columns[-12:], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_NP"
      ],
      "metadata": {
        "id": "hcHETh8zkSZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_NP.isnull().sum().sum() #Check if there are NA values"
      ],
      "metadata": {
        "id": "C8PEra5HfdD4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "890f6fb3-5d44-44b3-b693-5a433dec9bb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LtJLaEVvqfY"
      },
      "outputs": [],
      "source": [
        "import scipy.stats\n",
        "def correlation(dataset, threshold, target): #Function to get Pearson's correlation between input and target\n",
        "  data = []\n",
        "  for i in range(len(dataset.columns)):\n",
        "      cor2 = dataset.iloc[:,i].corr(target) #scipy.stats.spearmanr(x, y)[0] and scipy.stats.kendalltau(x, y)[0]\n",
        "      column_headers = list(dataset.columns.values)\n",
        "      if(abs(cor2) > threshold):\n",
        "        data.append(dataset.iloc[:,i]) #make list of columns that meet the threshold\n",
        "      i = i + 1\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngjdaqWIvssV"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from numpy.random.mtrand import random_sample\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV, ElasticNet, ElasticNetCV, MultiTaskLassoCV\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5q3JY8L1e1M"
      },
      "outputs": [],
      "source": [
        "def Scores(y, y_pred, y_full):\n",
        "  MSE = mean_squared_error(y, y_pred)\n",
        "  MAE = mean_absolute_error(y, y_pred)\n",
        "  Normalized_RMSE = (np.sqrt(MSE)/np.mean(y_full))*100\n",
        "  Normalized_MAE = (MAE/np.mean(y_full))*100\n",
        "  Avg_Normalized_Score = (Normalized_RMSE + Normalized_MAE)/2\n",
        "  print(f'Avg. Normalized Score:{ Avg_Normalized_Score:.1f}%')\n",
        "  #print(f'Normalized RMSE:{ Normalized_RMSE:.1f}%')\n",
        "  #print(f'Normalized MAE:{ Normalized_MAE:.2f}%')\n",
        "  #print(f'MAE:{ MAE:.3f}')\n",
        "  #print(f'RMSE:{ np.sqrt(MSE):.3f}')\n",
        "  return Avg_Normalized_Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLVl7ooxvt7q"
      },
      "outputs": [],
      "source": [
        "def RLE_Model(X, y, choice, predict_df): #Function to run Ridge, Lasso, or ElasticNet model\n",
        "  #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0) #Train/Test\n",
        "  X_train, X_test, y_train, y_test = X[10:30], X[0:10], y[10:30], y[0:10]\n",
        "\n",
        "  if(choice==\"Ridge\"):\n",
        "    alphas = np.geomspace(1e-10, 1e10, num=100)\n",
        "    pipeline = make_pipeline(RidgeCV(alphas=alphas))\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "  if(choice==\"Lasso\"):\n",
        "    alphas = np.geomspace(1e-10, 1e10, num=100)\n",
        "    pipeline = make_pipeline(LassoCV(alphas=alphas))\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "  if(choice==\"Elastic\"):\n",
        "    l1_ratio = [0, 0.3, 0.5, 0.7, 0.9, 1]\n",
        "    alphas = np.geomspace(1e-10, 1e10, num=100)\n",
        "    pipeline = make_pipeline(ElasticNetCV(alphas=alphas, l1_ratio=l1_ratio, max_iter=100000))\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "  #print(f'Chosen alpha  {pipeline.steps[0][1].alpha_:.6f}')\n",
        "  #print(f'Intercept (b) {pipeline.steps[0][1].intercept_:.6f}')\n",
        "  #print(pd.Series(pipeline.steps[0][1].coef_, index=X.columns),'\\n')\n",
        "\n",
        "  #Calculate the predicted values:\n",
        "  y_train_pred = pipeline.predict(X_train)\n",
        "  #print(y_train_pred)\n",
        "  print()\n",
        "\n",
        "  y_test_pred = pipeline.predict(X_test)\n",
        "\n",
        "  #Training Scores:\n",
        "  Avg_N_Score_train = Scores(y_train, y_train_pred, y)\n",
        "  #print()\n",
        "\n",
        "  #Test Predictions:\n",
        "  print(\"Test predictions:\")\n",
        "  print(y_test_pred)\n",
        "  #print()\n",
        "\n",
        "  #Testing Scores:\n",
        "  Avg_N_Score_test = Scores(y_test, y_test_pred, y)\n",
        "  print(f'Difference of avg scores:{ Avg_N_Score_test - Avg_N_Score_train:.3f}%') #Difference between testing and traing scores to check if my bias-variance tradeoff is good\n",
        "  print()\n",
        "\n",
        "  #Predict:\n",
        "  predictions = pipeline.predict(predict_df)\n",
        "\n",
        "  return y_test_pred, y_train_pred, predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpU87Mgvvx0s"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_regression\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def GBR_model(X,y, t, l, n, predict_df):\n",
        "  X_train, X_test, y_train, y_test = X[10:30], X[0:10], y[10:30], y[0:10]\n",
        "  reg = GradientBoostingRegressor(tol = t, learning_rate = l, n_estimators=n, random_state=0) #default: tol = 0.0001, learning rate - 0.1, 100, friedman_mse\n",
        "  reg.fit(X_train, y_train)\n",
        "  y_train_pred = reg.predict(X_train)\n",
        "  #print(y_train_pred)\n",
        "\n",
        "  y_test_pred = reg.predict(X_test)\n",
        "\n",
        "  #Training Scores:\n",
        "  Avg_N_Score_train = Scores(y_train, y_train_pred, y)\n",
        "  #print()\n",
        "\n",
        "  #Predictions:\n",
        "  print(\"Test predictions:\")\n",
        "  #print(y_test_pred)\n",
        "  #print()\n",
        "\n",
        "  #Testing Scores:\n",
        "  Avg_N_Score_test = Scores(y_test, y_test_pred, y)\n",
        "  print(f'Difference of avg scores:{ Avg_N_Score_test - Avg_N_Score_train:.3f}%') #Difference between testing and traing scores to check if my bias-variance tradeoff is good\n",
        "  print()\n",
        "\n",
        "  #Predict:\n",
        "  predictions = reg.predict(predict_df)\n",
        "  return y_test_pred, y_train_pred, predictions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingRegressor\n",
        "import xgboost as xgb\n",
        "import pickle\n",
        "\n",
        "def BR_model(X,y):\n",
        "  X_train, X_test, y_train, y_test = X[10:30], X[0:10], y[10:30], y[0:10]\n",
        "  reg = BaggingRegressor(base_estimator=xgb.XGBRegressor())\n",
        "  #reg = pickle.load(open(\"BR_model Per 100\", \"rb\"))\n",
        "  reg.fit(X_train, y_train)\n",
        "  y_train_pred = reg.predict(X_train)\n",
        "  #print(y_train_pred)\n",
        "\n",
        "  y_test_pred = reg.predict(X_test)\n",
        "\n",
        "  #Training Scores:\n",
        "  Avg_N_Score_train = Scores(y_train, y_train_pred, y)\n",
        "  #print()\n",
        "\n",
        "  #Predictions:\n",
        "  print(\"Test predictions:\")\n",
        "  #print(y_test_pred)\n",
        "  #print()\n",
        "\n",
        "  #Testing Scores:\n",
        "  Avg_N_Score_test = Scores(y_test, y_test_pred, y)\n",
        "  print(f'Difference of avg scores:{ Avg_N_Score_test - Avg_N_Score_train:.3f}%') #Difference between testing and traing scores to check if my bias-variance tradeoff is good\n",
        "  print()\n",
        "\n",
        "  #Predict:\n",
        "  #predictions = reg.predict(predict_df)\n",
        "  #print(predictions)\n",
        "\n",
        "  pickle.dump(reg, open(\"BR_model P%\", \"wb\"))\n",
        "  return y_test_pred, y_train_pred"
      ],
      "metadata": {
        "id": "ppib1skHfgGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfM5w0Ncvynu"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "#SGD Regressor:\n",
        "def SGD_model(X,y, t, ep):\n",
        "\n",
        "  reg = make_pipeline(SGDRegressor(max_iter=1000, tol=t, epsilon = ep)) #tol = 0.001, epsilon=0.1\n",
        "  X_train, X_test, y_train, y_test = X[10:30], X[0:10], y[10:30], y[0:10]\n",
        "  reg.fit(X_train, y_train)\n",
        "  y_train_pred = reg.predict(X_train)\n",
        "  #print(y_train_pred)\n",
        "\n",
        "  y_test_pred = reg.predict(X_test)\n",
        "\n",
        "  #Training Scores:\n",
        "  Avg_N_Score_train = Scores(y_train, y_train_pred, y)\n",
        "  #print()\n",
        "\n",
        "  #Predictions:\n",
        "  print(\"Test predictions:\")\n",
        "  #print(y_test_pred)\n",
        "  #print()\n",
        "\n",
        "  #Testing Scores:\n",
        "  Avg_N_Score_test = Scores(y_test, y_test_pred, y)\n",
        "  print(f'Difference of avg scores:{ Avg_N_Score_test - Avg_N_Score_train:.3f}%') #Difference between testing and traing scores to check if my bias-variance tradeoff is good\n",
        "  print()\n",
        "\n",
        "  #predictions = reg.predict(predict_df)\n",
        "  #print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Keras Sequential Neural Net\n",
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=2)\n",
        "\n",
        "def Keras_model(X,y,e, u, u2, u3, u4, u5):\n",
        "  X_train, X_test, y_train, y_test = X[10:30], X[0:10], y[10:30], y[0:10]\n",
        "  model = Sequential()\n",
        "  model.add(Dense(u, input_dim=X_train.shape[1], activation='relu')) # Hidden 1, 60\n",
        "  model.add(Dense(units=u2,activation='relu')) # Hidden 2, 30\n",
        "  model.add(Dense(units=u3,activation='relu'))\n",
        "  model.add(Dense(units=u4,activation='relu'))\n",
        "  model.add(Dense(units=u5,activation='relu'))\n",
        "  model.add(Dense(units=15,activation='relu')) #15\n",
        "  model.add(Dense(units=1)) #,activation='relu'\n",
        "  model.compile(loss='mean_squared_error', optimizer='nadam') #adam, nadam; adamax\n",
        "  m1 = model.fit(X_train, y_train, verbose=0, epochs=e, callbacks=[early_stop]); #callbacks=[early_stop]\n",
        "\n",
        "  y_train_pred = model.predict(X_train)\n",
        "  #print(y_train_pred)\n",
        "\n",
        "  y_test_pred = model.predict(X_test)\n",
        "\n",
        "  #Training Scores:\n",
        "  Avg_N_Score_train = Scores(y_train, y_train_pred, y)\n",
        "  #print()\n",
        "\n",
        "  #Predictions:\n",
        "  print(\"Test predictions:\")\n",
        "  #print(y_test_pred)\n",
        "  #print()\n",
        "\n",
        "  #Testing Scores:\n",
        "  Avg_N_Score_test = Scores(y_test, y_test_pred, y)\n",
        "  print(f'Difference of avg scores:{ Avg_N_Score_test - Avg_N_Score_train:.3f}%') #Difference between testing and traing scores to check if my bias-variance tradeoff is good\n",
        "  print()\n",
        "\n",
        "  #model.save('/content/drive/MyDrive/Models/Keras_Model', save_format=\"h5\")"
      ],
      "metadata": {
        "id": "Zzt-o4jPgtdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "def DTR_model(X,y,leafs):\n",
        "  X_train, X_test, y_train, y_test = X[10:30], X[0:10], y[10:30], y[0:10]\n",
        "  # We introduce regularization by increasing the value of min_samples_leaf\n",
        "  tree_reg_regularized = DecisionTreeRegressor(random_state=42, min_samples_leaf=leafs)\n",
        "  tree_reg_regularized.fit(X_train, y_train)\n",
        "  y_train_pred = tree_reg_regularized.predict(X_train) #_regularized\n",
        "  #print(y_train_pred)\n",
        "\n",
        "  y_test_pred = tree_reg_regularized.predict(X_test) #_regularized\n",
        "\n",
        "  #Training Scores:\n",
        "  Avg_N_Score_train = Scores(y_train, y_train_pred, y)\n",
        "  #print()\n",
        "\n",
        "  #Predictions:\n",
        "  print(\"Test predictions:\")\n",
        "  print(y_test_pred)\n",
        "  #print()\n",
        "\n",
        "  #Testing Scores:\n",
        "  Avg_N_Score_test = Scores(y_test, y_test_pred, y)\n",
        "  print(f'Difference of avg scores:{ Avg_N_Score_test - Avg_N_Score_train:.3f}%') #Difference between testing and traing scores to check if my bias-variance tradeoff is good\n",
        "  print()"
      ],
      "metadata": {
        "id": "sOg9t7czmLFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVR\n",
        "\n",
        "def SVM_model(X,y,ep):\n",
        "  X_train, X_test, y_train, y_test = X[10:30], X[0:10], y[10:30], y[0:10]\n",
        "  svm_reg = LinearSVR(epsilon=ep, random_state=42) #default: epsilon = 0 tol=0.0001, C=1.0\n",
        "  svm_reg.fit(X_train, y_train)\n",
        "\n",
        "  #Train Predictions:\n",
        "  y_train_pred = svm_reg.predict(X_train)\n",
        "  #print(y_train_pred)\n",
        "\n",
        "  #Training Scores:\n",
        "  Avg_N_Score_train = Scores(y_train, y_train_pred, y)\n",
        "  #print()\n",
        "\n",
        "  #Test Predictions:\n",
        "  y_test_pred = svm_reg.predict(X_test)\n",
        "  print(\"Test predictions:\")\n",
        "  print(y_test_pred)\n",
        "  #print()\n",
        "\n",
        "  #Testing Scores:\n",
        "  Avg_N_Score_test = Scores(y_test, y_test_pred, y)\n",
        "  print(f'Difference of avg scores:{ Avg_N_Score_test - Avg_N_Score_train:.3f}%') #Difference between testing and traing scores to check if my bias-variance tradeoff is good\n",
        "  print()"
      ],
      "metadata": {
        "id": "luksQpOa9mx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "def SVM_models(X,y, choice, ep, C_value, predict_df):\n",
        "  X_train, X_test, y_train, y_test = X[10:30], X[0:10], y[10:30], y[0:10]\n",
        "\n",
        "  if(choice==\"rbf\"):\n",
        "    model = SVR(kernel=\"rbf\", C=C_value, gamma=0.1, epsilon=ep) #0.1 default ep; 100 default C, 0.1 default gamma\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "  if(choice==\"poly\"):\n",
        "    model = SVR(kernel=\"poly\", C=C_value, gamma=\"auto\", degree=3, epsilon=ep, coef0=1) #0.1 default ep; 100 default C\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "  if(choice == \"linear\"):\n",
        "    model = SVR(kernel=\"linear\", C=C_value, gamma=\"auto\", degree=3, epsilon=ep, coef0=1) #0.1 default ep; 100 default C\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "  #Train Predictions:\n",
        "  y_train_pred = model.predict(X_train)\n",
        "  #print(y_train_pred)\n",
        "\n",
        "  #Training Scores:\n",
        "  Avg_N_Score_train = Scores(y_train, y_train_pred, y)\n",
        "  #print()\n",
        "\n",
        "  #Test Predictions:\n",
        "  y_test_pred = model.predict(X_test)\n",
        "  print(\"Test predictions:\")\n",
        "  print(y_test_pred)\n",
        "  #print()\n",
        "\n",
        "  #Testing Scores:\n",
        "  Avg_N_Score_test = Scores(y_test, y_test_pred, y)\n",
        "  print(f'Difference of avg scores:{ Avg_N_Score_test - Avg_N_Score_train:.3f}%') #Difference between testing and traing scores to check if my bias-variance tradeoff is good\n",
        "  print()\n",
        "\n",
        "  final_preds = model.predict(predict_df)\n",
        "\n",
        "  return y_test_pred, y_train_pred, final_preds"
      ],
      "metadata": {
        "id": "1ms2SSQ_3ncH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#In case I wanted to add these values to data frame of inputs\n",
        "scaler = StandardScaler()\n",
        "S = df_22[\"Avg/SOS_ScoringD\"].values\n",
        "S3 = S.reshape(-1, 1)\n",
        "data_scaledOPPG = scaler.fit_transform(S3)"
      ],
      "metadata": {
        "id": "ilrGRE6eLa_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_swiss_roll\n",
        "from sklearn.manifold import LocallyLinearEmbedding"
      ],
      "metadata": {
        "id": "UhxkZpeNTZA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[:, 203:]"
      ],
      "metadata": {
        "id": "GQ1MImLOcqjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "RJSe6xMvwg_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature Importance:\n",
        "scaler = StandardScaler() #MinMaxScaler()\n",
        "data_scaled = pd.DataFrame(scaler.fit_transform(df_NP[10:30]), columns = df_NP.columns)\n",
        "data_correlated = correlation(data_scaled, .26, df['GF/GA_Playoffs']) #.115 lowest for All csv\n",
        "data_correlated_df = pd.DataFrame(data_correlated)\n",
        "data_correlated_df2 = data_correlated_df.transpose() #Correlated inputs\n",
        "X = df_NP.loc[:, data_correlated_df2.columns] #get non scaled data with important features\n",
        "\n",
        "#Train test split and scale:\n",
        "X_train, X_test = X[10:30], X[0:10]\n",
        "X_train_processed = pd.DataFrame(scaler.fit_transform(X_train), columns = X_train.columns)\n",
        "X_test_processed = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)\n",
        "correlated_scaled_data = pd.merge(X_train_processed, X_test_processed, how = 'outer')\n",
        "\n",
        "#PCA:\n",
        "pca=PCA(n_components = 10)\n",
        "X_train_processed_PCA = pca.fit_transform(X_train_processed)\n",
        "X_train_PCA_df = pd.DataFrame(X_train_processed_PCA)\n",
        "X_test_processed_PCA = pca.fit_transform(X_test_processed)\n",
        "X_test_PCA_df = pd.DataFrame(X_test_processed_PCA)\n",
        "data_PCA = pd.merge(X_test_PCA_df, X_train_PCA_df, how = 'outer')\n",
        "print(\"Principal axes:\\n\", pca.components_.tolist())\n",
        "print(\"Explained variance:\\n\", pca.explained_variance_.tolist())\n",
        "print(\"Mean:\", pca.mean_)\n",
        "\n",
        "#LLE:\n",
        "#X_swiss, t = make_swiss_roll(n_samples=1000, noise=0.2, random_state=42)\n",
        "lle = LocallyLinearEmbedding(n_components=2, n_neighbors=15, random_state=42) #n_components=2 is default, neighbors 5 is default\n",
        "X_unrolled_train = lle.fit_transform(X_train_processed)\n",
        "X_train_LLE_df = pd.DataFrame(X_unrolled_train)\n",
        "X_unrolled_test = lle.transform(X_test_processed)\n",
        "X_test_LLE_df = pd.DataFrame(X_unrolled_test)\n",
        "data_LLE = pd.merge(X_test_LLE_df, X_train_LLE_df, how = 'outer')\n",
        "\n",
        "X = correlated_scaled_data #try correlated_scaled_data, data_PCA, or data_LLE\n",
        "y = df['GF/GA_Playoffs'] #"
      ],
      "metadata": {
        "id": "Z0RXs3FQMoHz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7217f9a-d7b3-44e8-c6bf-77fb8255a4ad"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Principal axes:\n",
            " [[-0.23686773926600255, -0.16888537292094707, 0.2099359535329454, -0.3312313593159493, 0.326082373419008, -0.005782803197161005, -0.09802820239206782, 0.17093969547710797, -0.009563303152510286, -0.005782803197160942, -0.3420942964624609, -0.170920822985746, -0.28922372677805014, 0.17093969547710805, -0.14735458038942914, 0.047121903571578964, 0.04455297032701621, 0.018292090463592127, 0.014147313480410983, 0.05271409445254018, 0.04967471136371828, 0.0323167162906176, 0.03550698459722833, -0.5683805603212041, -0.009563303152510347], [0.02924799332642015, 0.0002401486596886621, 0.0276527562582351, -0.1827987645663812, -0.037461013771347196, -0.23888539378961243, -0.026014644822003823, -0.01963790381919664, 0.08561149663832603, -0.23888539378961238, -0.20228463107724115, 0.00024304299326222562, 0.060282571882730694, -0.01963790381919664, 0.051176622870761086, 0.0670192883459234, 0.06185986560826507, 0.38123819386562596, 0.38596241932910774, 0.060022370971220505, 0.0632201932578496, 0.4539905447392455, 0.4537094213568838, 0.2529087884376302, 0.08561149663832603], [0.29311128497843497, -0.18085949801679882, 0.010164114192707768, -0.2369770936916651, -0.21815759769859688, -0.04016482203095513, 0.18675210111195023, -0.11436310686041445, -0.05739884685792962, -0.04016482203095515, 0.06825414664416289, -0.18303926332501236, -0.1893593863071286, -0.11436310686041451, -0.13460499613605542, 0.3990632053837097, 0.3880761110221247, -0.10500054868236292, -0.10604947246362424, 0.36288610756515843, 0.3528183343402779, -0.0841387307396868, -0.08787606198662133, 0.10695479202903821, -0.05739884685792958], [-0.3915021354994684, 0.3320309636337594, -0.3813365404440476, 0.12867203608070782, 0.014510300049017695, -0.04440149145624214, -0.12143262987151529, 0.007606624809717391, -0.18274588756629587, -0.044401491456242136, -0.1497327558637061, 0.33603268642807094, 0.24262777619406398, 0.007606624809717386, 0.11978039042648106, 0.2875062620999192, 0.2850880714546738, 0.011499097197882759, 0.006827084616736356, 0.1973311910970042, 0.19499973339980123, -0.0177686759134078, -0.01849475842225515, -0.1959862005142349, -0.1827458875662959], [0.062493901383036586, -0.09301349621641293, -0.13252537204807976, 0.24680906940955094, 0.5892312718003364, 0.15652617777115005, -0.19139706352741717, 0.30888825149009785, 0.0074147213320631105, 0.15652617777115016, 0.18899410423891239, -0.09413451885813984, -0.1253048556023213, 0.3088882514900979, -0.0003939144963762961, 0.1180507455711169, 0.12206207068338032, 0.022230646556766275, 0.02724109079495663, 0.13586083745269714, 0.13406811199326996, 0.05028282678085308, 0.04975185753580422, 0.39168259010206574, 0.007414721332063029], [0.11393123370574343, 0.1289951497267822, 0.09058012683894183, -0.4052516220714869, 0.30733195393920953, -0.2883002891309011, 0.3226454388816523, 0.16111030493895026, -0.245750273885187, -0.288300289130901, -0.07077551537858785, 0.13054983253518043, 0.17284464868591787, 0.16111030493895037, 0.21789647689157457, -0.13046247038849237, -0.11133253788213886, -0.16415537996158258, -0.16211024287487266, -0.009461143310971061, -0.01021914751489202, -0.10529161552057346, -0.11851252860974582, 0.23040298163291476, -0.2457502738851871], [0.22705380110811052, 0.19548950481595417, 0.04454650223266034, 0.08757875498556575, 0.09505340685745087, -0.09361070725135709, 0.2342055910290741, 0.04982912830248416, -0.14949268792926948, -0.09361070725135702, 0.633958014790528, 0.19784559473874108, -0.18176749584062227, 0.04982912830248413, -0.1385300107458552, 0.025410049711135516, 0.023619994320213288, 0.1554518344430222, 0.15814274372032766, -0.02717180998456358, -0.036362058887487544, 0.15318996508041066, 0.14320357166964243, -0.42404257560915476, -0.14949268792926942], [-0.04936471253801594, -0.026165586255502783, 0.5838321175125455, 0.3129264915881223, -0.10572062257148568, 0.04928688660202622, -0.18991903388929438, -0.05542112208806243, -0.47193743481973965, 0.04928688660202621, -0.13277322766773333, -0.02648094064835592, -0.048332265125071085, -0.05542112208806244, -0.029273271597099887, 0.03887001967530606, 0.037579601349101384, 0.04619528406511752, 0.05348896706632324, -0.009506686115463538, -0.01858134351164781, 0.030522005242307543, 0.0463096938073551, 0.14644207501763587, -0.4719374348197396], [-0.035564347075064874, 0.045733320594918546, -0.1021448212640762, -0.26364003207002373, 0.0010591763329842576, 0.5199326829085541, 0.4847384149633691, 0.0005552439953082371, -0.14611644990355496, 0.5199326829085539, -0.12730982526111148, 0.04628451036794897, 0.09032625265379193, 0.0005552439953083905, -0.033217211336452515, -0.011874617273466575, 0.008395341506443063, 0.15029173716136665, 0.12253404482619054, -0.05688137308157228, -0.044653298646973164, 0.11986642737524889, 0.09528991908952213, 0.06532557533175437, -0.14611644990355505], [-0.2714518440234284, 0.33288785464590415, 0.46124409272850486, 0.15861034475956742, -0.056029208504082176, -0.14987236884544164, 0.3356944432088496, 0.07005037526635219, 0.33009073224237806, 0.13668761837282573, -0.036340292057182706, 0.18579654529761266, -0.07130744729367469, 0.20579581820369658, -0.1736615797100796, 0.19003964050262337, -0.08333118502594951, 0.019329711584846816, -0.05329436021859185, 0.029751713702395304, 0.2178780251392347, 0.005731905198700085, -0.13170138005056642, 0.1452418916539698, 0.24538872907651044]]\n",
            "Explained variance:\n",
            " [4.149020861585804, 3.008880665161881, 2.7783406569674716, 1.6722395024443553, 1.2473387155724684, 0.9601254603935815, 0.6962467975111422, 0.27720342879730253, 0.03174897094020703, 1.548325152205069e-31]\n",
            "Mean: [ 1.40028008e-01  1.01498101e+00 -1.69660673e+00  4.04750390e-01\n",
            " -2.66453526e-16 -4.36852028e-01  5.95673005e-01 -8.73704057e-02\n",
            "  2.24230528e-01 -4.36852028e-01  5.66981744e-01  1.06203463e+00\n",
            "  1.29881326e+00 -8.73704057e-02  9.64351793e-01  5.92986578e-01\n",
            "  6.07410322e-01 -1.21701456e-01 -1.09549896e-01  4.00734023e-01\n",
            "  3.97519107e-01 -1.49415998e-01 -1.41744168e-01  1.15311332e+00\n",
            "  2.24230528e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data_correlated)"
      ],
      "metadata": {
        "id": "zCYcvQ1wa8Bn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ef15a1e-5c9e-4da1-8df9-07e0bddea2d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_correlated"
      ],
      "metadata": {
        "id": "nmz4ZAM-YMW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.to_excel(\"GF_GA.xlsx\")"
      ],
      "metadata": {
        "id": "CzZhtFgUwfhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**P%**"
      ],
      "metadata": {
        "id": "5shDpDOhXFI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Model: (P%_Playoffs) .395\n",
        "RLE_Model(X, y, \"Ridge\", X) #6.2%, 1.1%, correlated\n",
        "RLE_Model(X, y, \"Lasso\", X) #\n",
        "SGD_model(X,y, 1e-3, 0.1) #\n",
        "GBR_model(X,y, .0001, 0.01, 100, X) #7.8%, 2.5%, LLE\n",
        "print(\"5:\")\n",
        "DTR_model(X,y, 100) #"
      ],
      "metadata": {
        "id": "sZiNfyW6tIpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SVM_models(X, y, \"poly\", .1, 100, X) #6.9%, 1.1%, correlated\n",
        "SVM_models(X, y, \"linear\", .1, 100, X) #6.8%, 1.3%, correlated\n",
        "SVM_model(X,y, 0.0) #"
      ],
      "metadata": {
        "id": "9eGYjBc_-JxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RLE_Model(X, y, \"Elastic\") #\n",
        "BR_model(X,y) #5.6%, 2.7%, correlated\n",
        "Keras_model(X, y, 200, 120, 60, 30, 20, 15) #"
      ],
      "metadata": {
        "id": "9sZlCeWYWM01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#P% Blender: 5.9%, .1%\n",
        "predict_P = pd.read_csv('P%_inputs.csv')\n",
        "scaled_data = scaler.transform(predict_P)\n",
        "predict_unrolled = pd.DataFrame(lle.transform(scaled_data))\n",
        "loaded_BR_model = pickle.load(open(\"BR_model P%\", \"rb\"))\n",
        "\n",
        "X = correlated_scaled_data\n",
        "preds = (loaded_BR_model.predict(X[0:10]), loaded_BR_model.predict(X[10:30]), loaded_BR_model.predict(predict_P)) #5.6%, 2.7%, correlated\n",
        "preds2 = RLE_Model(X, y, \"Ridge\", scaled_data) #6.2%, 1.1%, correlated\n",
        "preds3 = SVM_models(X, y, \"linear\", .1, 100, scaled_data) #6.8%, 1.3%, correlated\n",
        "\n",
        "train_preds = (preds[1] + preds2[1] + preds3[1])/3\n",
        "test_preds = (preds[0] + preds2[0] + preds3[0])/3 #5.9%, .1%\n",
        "\n",
        "print(\"Blender Train Scores then Test Scores:\")\n",
        "Scores(y[10:30], train_preds, y)\n",
        "print()\n",
        "Scores(y[0:10], test_preds, y)\n",
        "print()\n",
        "\n",
        "P_predictions = pd.DataFrame()\n",
        "P_predictions[\"Predictions\"] = (preds[2] + preds2[2] + preds3[2])/3\n",
        "P_predictions.to_excel(\"P%_Predictions.xlsx\")"
      ],
      "metadata": {
        "id": "JA896fu7cbDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Per GM**"
      ],
      "metadata": {
        "id": "8eNDh3THXH4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Model: (GF/GA_Playoffs) .26\n",
        "RLE_Model(X, y, \"Ridge\", X) #13%, 2.6%, correlated\n",
        "RLE_Model(X, y, \"Lasso\", X) #\n",
        "SGD_model(X,y, 1e-3, 0.1)\n",
        "GBR_model(X,y, .0001, 0.01, 100, X) #\n",
        "print(\"5:\")\n",
        "DTR_model(X,y, 100) #"
      ],
      "metadata": {
        "id": "8YZMdaOZpLVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SVM_models(X, y, \"rbf\", .1, 100, X) #\n",
        "SVM_models(X, y, \"poly\", .08, 500, X) #10.7%, 3.1%, LLE\n",
        "SVM_models(X, y, \"linear\", .05, 100, X) #13.8%, 2.4%, LLE\n",
        "SVM_model(X,y, 0) #13.7%, 2.5%, LLE"
      ],
      "metadata": {
        "id": "DvWjsOsO_5M2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RLE_Model(X, y, \"Elastic\", X) #13.1, 2.6%, correlated\n",
        "BR_model(X,y) #\n",
        "Keras_model(X, y, 200, 120, 60, 30, 20, 15) #"
      ],
      "metadata": {
        "id": "Ddbf8Qe0pLZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GF/GA Blender:\n",
        "predict_GF_GA = pd.read_csv('GF_GA.csv')\n",
        "predict_GF_GA.drop(\"Unnamed: 0\", axis = 1, inplace = True)\n",
        "scaled_data = scaler.transform(predict_GF_GA)\n",
        "predict_unrolled = pd.DataFrame(lle.transform(scaled_data))\n",
        "\n",
        "X = correlated_scaled_data\n",
        "preds2 = RLE_Model(X, y, \"Ridge\", scaled_data) #13%, 2.6%, correlated\n",
        "#preds3 = RLE_Model(X, y, \"Elastic\", scaled_data) #13.1, 2.6%, correlated\n",
        "\n",
        "X = data_LLE\n",
        "preds = SVM_models(X, y, \"poly\", .08, 500, predict_unrolled) #10.7%, 3.1%, LLE\n",
        "preds4 = SVM_models(X, y, \"linear\", .05, 100, predict_unrolled) #13.8%, 2.4%, LLE\n",
        "\n",
        "train_preds = (preds[1] + preds2[1])/2\n",
        "test_preds = (preds[0] + preds2[0])/2 #11.1%, 2.7%\n",
        "\n",
        "print(\"Blender Train Scores then Test Scores:\")\n",
        "Scores(y[10:30], train_preds, y)\n",
        "print()\n",
        "Scores(y[0:10], test_preds, y)\n",
        "print()\n",
        "\n",
        "GF_GA_predictions = pd.DataFrame()\n",
        "GF_GA_predictions[\"Predictions\"] = preds[2]\n",
        "GF_GA_predictions[\"Predictions2\"] = (preds[2] + preds2[2])/2\n",
        "GF_GA_predictions.to_excel(\"GF_GA_Predictions.xlsx\")"
      ],
      "metadata": {
        "id": "6VkschS-s6tE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check for collinearity\n",
        "import seaborn as sns\n",
        "#sns.pairplot(data_correlated_df2)\n",
        "\n",
        "corr = data_correlated_df2.corr()\n",
        "print(corr)"
      ],
      "metadata": {
        "id": "TyALuH9TPDdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get Pearson's correlation between 2 variables\n",
        "df_16.iloc[:,-3].corr(df_Playoffs_16.iloc[:,-2])"
      ],
      "metadata": {
        "id": "mmHqjfoXJx3W"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}